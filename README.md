# Fake News Classifier
## COMP 432 Machine Learning - Term Project
### A comparison between traditional ML models and Deep Learning in text classification

### Submitted by:
#### Giselle Martel - 26352936
#### Firas Sawan - 26487815

This project focuses on various machine learning & deep learning models in the task of text classification, specifically the classification of news as "Fake News" or "Real News"

The Following Models are trained on the included datasets:

- Logistic Regression Classifier
- Decision Tree Classifier
- Random Forest Classifier
- Support Vector Machine Classifier
- Naive Bayes Classifier
- Convolutional Neural Network

## Dependencies

### You will need to install the following dependencies:
## *Please use version 3.8 of python*
- numpy
- matplotlib
- pandas
- sklearn
- feedparser
- newspaper
- nltk
- seaborn
- pytorch
- datetime

### Run the following command to install all dependencies:
`python -m pip install numpy pandas matplotlib sklearn feedparser newspaper3k nltk seaborn torch datetime`

## File Structure Overview
The code is organized into the following structure:

- `FakeNewsClassifier`                                         -- root folder
    - `./main.py`                                                  -- script to run the program and save results to .png and .txt files in `./results`
    - `./fake_news_classifiers.ipynb`                              -- jupyter notebook to run and visualize all the models
    - `./preprocess.py`                                            -- contains all the preprocessing scripts for the raw datasets
    - `./data`                                                   -- contains both the raw and preprocessing data   
    - `./data/mock_data`                                      -- contains data for the mock run (for faster execution but inaccurate results) 
        - `./data/mock_data/kaggle_raw`                        -- contains the raw datasets obtained from kaggle
            - `./data/mock_data/kaggle_raw/True.csv`           -- *miniaturized* "real" new sources data from kaggle
            - `./data/mock_data/kaggle_raw/Fake.csv`           -- *miniaturized* "fake" new sources data from kaggle
        - `./data/real_data/scraped_raw`                       -- contains raw data scraped from online news sources
            - `./data/real_data/scraped_raw/news_sources.json`  -- json file containing a mapping of all the news sources to scrape raw data from
            - `./data/real_data/scraped_raw/scraped_articles.json`   -- json file containing all the raw scraped news data generated by the script `./tools/scrape_data.py`
        - `./data/mock_data/preprocessed`                       -- preprocessed data generated by the scripts in `./preprocessing.py` will stored here as .csv files
    - `./data/real_data`                                      -- contains the true raw datasets and preprocessed data
        - `./data/real_data/kaggle_raw`                        -- contains the raw datasets obtained from kaggle
            - `./data/real_data/kaggle_raw/True.csv`           -- "real" new sources data from kaggle
            - `./data/real_data/kaggle_raw/Fake.csv`           -- "fake" new sources data from kaggle
        - `./data/real_data/scraped_raw`                       -- contains raw data scraped from online news sources
            - `./data/real_data/scraped_raw/news_sources.json`  -- json file containing a mapping of all the news sources to scrape raw data from
            - `./data/real_data/scraped_raw/scraped_articles.json`   -- json file containing all the raw scraped news data generated by the script `./tools/scrape_data.py`
        - `./data/real_data/preprocessed`                       -- preprocessed data generated by the scripts in `./preprocessing.py` will stored here as .csv files
    - `./model`                                                -- contains the implementations of the various ML models
        - `./model/convolutional_neural_network.py`
        - `./model/decision_tree.py`
        - `./model/logistic_regression.py`
        - `./model/naive_bayesian_classifier.py`
        - `./model/random_forest.py`
        - `./model/support_vector_machine.py`
    - `./results`                                                -- contains the results of the classifications organized into 1 subfolder per model
        - `./cached_results`                                     -- contains cached results of the classifier predictions from previous program execution, organized into 1 subfolder per model
        - `./results/mock_results`
            - `./results/mock_results/CNN`
            - `./results/mock_results/DecisionTree`
            - `./results/mock_results/LogisticRegression`
            - `./results/mock_results/NaiveBayes`
            - `./results/mock_results/RandomForest`
            - `./results/mock_results/SVC`
        - `./results/real_results`
            - `./results/mock_results/CNN`
            - `./results/mock_results/DecisionTree`
            - `./results/mock_results/LogisticRegression`
            - `./results/mock_results/NaiveBayes`
            - `./results/mock_results/RandomForest`
            - `./results/mock_results/SVC`
    - `./tools`                                                    -- contains various utilities for the program
        - `./ascii_art.py`                                         -- for fun console output
        - `./scrape_data.py`                                       -- script for scraping news articles from the web
        - `./tools.py`                                             -- helper functions for displaying, graphing, and saving the results of the classifiers 

## To Run
There are 2 options to run and test the program.

### Jupyter Notebook
- to run the notebook, run the following in the root folder: `jupyter notebook`
- the notebook already contains all the saved results of running each of the classifiers
- does not save results to `./results` folder, but can save the output state of the notebook
- full dataset takes ~40-60 to train and classify

### Regular Python program
- to run the main python application, run the following in the root folder: `python main.py`
- allows you to run the program with a minaturized dataset or the full dataset (follow program prompts)
- saves all results to `./results` folder
- full dataset takes ~40-60 to train and classify

### Updating the Scraped Data (optional)
- if you wish to update the scraped data, you will need to run the script in the `./tools` subfolder: `python tools/scrape_data.py`
- note that this script ~30 min to scrape all the data
- you can find the raw scraped data at: `./data/real_data/scraped_raw/scraped_articles.json`
- To use the data, simply run the program again with the full dataset to tokenize and classify the updated data

## Datasets

### Kaggle
- the kaggle dataset was downloaded from here: https://www.kaggle.com/clmentbisaillon/fake-and-real-news-dataset

### Scraped data
- please refer to `./data/real_data/scraped_raw/news_sources.json` to see all the sources of the scraped data

## References
### Scrapping, Preprocessing, and Training of Data relied on the following sources:
- https://github.com/riag123/FakeNewsDeepLearning
- https://towardsdatascience.com/getting-real-with-fake-news-d4bc033eb38a

### Convolutional Neural Network Implementation relied on the following sources:
- https://towardsdatascience.com/text-classification-with-cnns-in-pytorch-1113df31e79f?sk=12e7c4b3092297ee0e1c71d659297043
- https://github.com/FernandoLpz/Text-Classification-CNN-PyTorch


