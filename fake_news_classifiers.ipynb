{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 432 Project - Fall 2020\n",
    "\n",
    "#### Student Names:\n",
    "#### Firas Sawan       ID#26487815 \n",
    "#### Giselle Martel    ID#26352936"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FakeNewsClassifiers\n",
    "\n",
    "##### A comparison between different Machine Learning models in predicting which news articles are \"Fake News\" or \"Real News\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tools as tools\n",
    "import preprocess as preprocess\n",
    "import model.logistic_regression as LR\n",
    "import model.decision_tree as DT\n",
    "import model.random_forest as RF\n",
    "import model.support_vector_machine as SVC\n",
    "import model.naive_bayesian_classifier as NB\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Processing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nPreprocessing of data...\\n\")\n",
    "\n",
    "# read dataset from csv files\n",
    "fake_news = preprocess.parse_dataset(\"Fake_test.csv\", \"FAKE\")\n",
    "real_news = preprocess.parse_dataset(\"True_test.csv\", \"REAL\")\n",
    "\n",
    "print()\n",
    "\n",
    "# join all news (fake + real) data\n",
    "all_news = pd.concat([fake_news, real_news], axis=0)\n",
    "\n",
    "# tokenize each dataset\n",
    "fake_news_all_tokens, fake_news_tokens_per_article = preprocess.tokenize(fake_news, \"fake_news\")\n",
    "real_news_all_tokens, real_news_tokens_per_article = preprocess.tokenize(real_news, \"real_news\")\n",
    "\n",
    "print()\n",
    "\n",
    "# join tokens (fake + real)\n",
    "all_tokens = fake_news_all_tokens + real_news_all_tokens\n",
    "tokens_per_article = fake_news_tokens_per_article + real_news_tokens_per_article\n",
    "\n",
    "print()\n",
    "\n",
    "# Split and preprocess the data into training and testing data\n",
    "X_train, X_test, y_train, y_test = preprocess.split_and_preprocess(all_tokens,tokens_per_article, all_news)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "# Logisitic Regression Classifier\n",
    "print(\"\\nTesting Logistic Regression Classifier ...\\n\")\n",
    "\n",
    "# set the hyperparams\n",
    "C = np.logspace(-4,4,6)\n",
    "\n",
    "# perform hyperparam search\n",
    "estimators, accuracy, best_estimator, hyperparams = LR.logisitic_regression_hyperparam_search(X_train, y_train, C)\n",
    "\n",
    "# calculate the training and testing scores and plot the result\n",
    "trn_scores, test_scores = tools.calculate_estimator_scores([X_train, X_test, y_train, y_test], estimators)\n",
    "\n",
    "# calculate model overfitting\n",
    "overfitting = tools.determine_overfitting(trn_scores,test_scores)\n",
    "print(\"\\nLogistic Regression overfitting: {:.3f}\\n\".format(overfitting))\n",
    "\n",
    "# plot the scores of each estimator\n",
    "tools.plot_estimator_scores(\"LogisticRegression\",trn_scores,test_scores)\n",
    "\n",
    "# display details of best estimator\n",
    "tools.display_best_estimator(accuracy, \"LogisticRegression\", hyperparams)\n",
    "\n",
    "# use best estimator to make predictions\n",
    "y_pred = LR.logistic_regression_predict(best_estimator, X_test)\n",
    "\n",
    "tools.plot_predicted_labels(y_test, y_pred, \"LogisticRegression\")\n",
    "tools.display_prediction_scores(y_test,y_pred)\n",
    "tools.plot_confusion_matrix(y_test,y_pred,\"LogisticRegression\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "# Random Forest Classifer\n",
    "print(\"\\nTesting Random Forest Classifier ...\\n\")\n",
    "\n",
    "# set the hyperparams\n",
    "D = np.linspace(1,1000,20)\n",
    "N = np.linspace(1,10,1, dtype=\"int32\")\n",
    "\n",
    "# perform hyperparam search\n",
    "estimators, accuracy, best_estimator, hyperparams = RF.random_forest_hyperparam_search(X_train, y_train, D, N)\n",
    "\n",
    "# calculate the training and testing scores and plot the result\n",
    "trn_scores, test_scores = tools.calculate_estimator_scores([X_train, X_test, y_train, y_test], estimators)\n",
    "\n",
    "# calculate model overfitting\n",
    "overfitting = tools.determine_overfitting(trn_scores,test_scores)\n",
    "print(\"\\nRandom Forest overfitting: {:.3f}\\n\".format(overfitting))\n",
    "\n",
    "# plot the scores of each estimator\n",
    "tools.plot_estimator_scores(\"RandomForest\",trn_scores,test_scores)\n",
    "\n",
    "# display details of best estimator\n",
    "tools.display_best_estimator(accuracy, \"RandomForest\", hyperparams)\n",
    "\n",
    "# use best estimator to make predictions\n",
    "y_pred = RF.random_forest_predict(best_estimator, X_test)\n",
    "\n",
    "tools.plot_predicted_labels(y_test, y_pred, \"RandomForest\")\n",
    "tools.display_prediction_scores(y_test,y_pred)\n",
    "tools.plot_confusion_matrix(y_test,y_pred,\"RandomForest\")\n",
    "\n",
    "tools.display_result(best_estimator, X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "print(\"\\nTesting Decision Tree Classifier ...\\n\")\n",
    "\n",
    "# set the hyperparams\n",
    "D = np.linspace(1,18,3)\n",
    "\n",
    "# perform hyperparam search\n",
    "estimators, accuracy, best_estimator, hyperparams = DT.decision_tree_hyperparam_search(X_train, y_train, D)\n",
    "\n",
    "# calculate the training and testing scores and plot the result\n",
    "trn_scores, test_scores = tools.calculate_estimator_scores([X_train, X_test, y_train, y_test], estimators)\n",
    "\n",
    "# calculate model overfitting\n",
    "overfitting = tools.determine_overfitting(trn_scores,test_scores)\n",
    "print(\"\\nDecision Tree overfitting: {:.3f}\\n\".format(overfitting))\n",
    "\n",
    "# plot the scores of each estimator\n",
    "tools.plot_estimator_scores(\"DecisionTree\",trn_scores,test_scores)\n",
    "\n",
    "# display details of best estimator\n",
    "tools.display_best_estimator(accuracy, \"DecisionTree\", hyperparams)\n",
    "\n",
    "# use best estimator to make predictions\n",
    "y_pred = DT.decision_tree_predict(best_estimator, X_test)\n",
    "\n",
    "tools.plot_predicted_labels(y_test, y_pred, \"DecisionTree\")\n",
    "tools.display_prediction_scores(y_test,y_pred)\n",
    "tools.plot_confusion_matrix(y_test,y_pred,\"DecisionTree\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "# Naive Bayes Classifier\n",
    "print(\"\\nTesting Naive Bayesian Classifier ...\\n\")\n",
    "\n",
    "# set the hyperparams\n",
    "A = np.linspace(0.05,1,12)\n",
    "F = [True, False]\n",
    "\n",
    "# perform hyperparam search\n",
    "estimators, accuracy, best_estimator, hyperparams = NB.naive_bayes_hyperparam_search(X_train, y_train, A,F)\n",
    "\n",
    "# calculate the training and testing scores and plot the result\n",
    "trn_scores, test_scores = tools.calculate_estimator_scores([X_train, X_test, y_train, y_test], estimators)\n",
    "\n",
    "# calculate model overfitting\n",
    "overfitting = tools.determine_overfitting(trn_scores,test_scores)\n",
    "print(\"\\nNaive Bayes overfitting: {:.3f}\\n\".format(overfitting))\n",
    "\n",
    "# plot the scores of each estimator\n",
    "tools.plot_estimator_scores(\"NaiveBayes\",trn_scores,test_scores)\n",
    "\n",
    "# display details of best estimator\n",
    "tools.display_best_estimator(accuracy, \"NaiveBayes\", hyperparams)\n",
    "\n",
    "# use best estimator to make predictions\n",
    "y_pred = NB.naive_bayesian_predict(best_estimator, X_test)\n",
    "\n",
    "tools.plot_predicted_labels(y_test, y_pred, \"NaiveBayes\")\n",
    "tools.display_prediction_scores(y_test,y_pred)\n",
    "tools.plot_confusion_matrix(y_test,y_pred,\"NaiveBayes\")\n",
    "\n",
    "tools.display_result(best_estimator, X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "# Support Vector Classification\n",
    "print(\"\\nTesting SVM Classifier ...\\n\")\n",
    "\n",
    "# set the hyperparams\n",
    "C = np.logspace(-4,4,6)\n",
    "G = np.logspace(-4,4,6)\n",
    "K = [\"rbf\", \"linear\"]\n",
    "\n",
    "# perform hyperparam search\n",
    "estimators, accuracy, best_estimator, hyperparams = SVC.svc_hyperparam_search(X_train, y_train, C, G, K)\n",
    "\n",
    "# calculate the training and testing scores and plot the result\n",
    "trn_scores, test_scores = tools.calculate_estimator_scores([X_train, X_test, y_train, y_test], estimators)\n",
    "\n",
    "# calculate model overfitting\n",
    "overfitting = tools.determine_overfitting(trn_scores,test_scores)\n",
    "print(\"\\nSVC overfitting: {:.3f}\\n\".format(overfitting))\n",
    "\n",
    "# plot the scores of each estimator\n",
    "tools.plot_estimator_scores(\"SVC\",trn_scores,test_scores)\n",
    "\n",
    "# display details of best estimator\n",
    "tools.display_best_estimator(accuracy, \"SVC\", hyperparams)\n",
    "\n",
    "# use best estimator to make predictions\n",
    "y_pred = SVC.support_vector_machine_predict(best_estimator, X_test)\n",
    "\n",
    "tools.plot_predicted_labels(y_test, y_pred, \"SVC\")\n",
    "tools.display_prediction_scores(y_test,y_pred)\n",
    "tools.plot_confusion_matrix(y_test,y_pred,\"SVC\")\n",
    "\n",
    "tools.display_result(best_estimator, X_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
