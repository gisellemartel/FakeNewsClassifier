{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP 432 Machine Learning - Term Project Fall 2020\n",
    "\n",
    "#### Student Names:\n",
    "#### Firas Sawan       ID#26487815 \n",
    "#### Giselle Martel    ID#26352936"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FakeNewsClassifiers\n",
    "\n",
    "##### A comparison between different Machine Learning and Deep Learning models in predicting which news articles are \"Fake News\" or \"Real News\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/gisellemartel/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/gisellemartel/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/gisellemartel/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f908972f210>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tools.tools as tools\n",
    "import preprocess as preprocess\n",
    "import model.logistic_regression as LR\n",
    "import model.decision_tree as DT\n",
    "import model.random_forest as RF\n",
    "import model.support_vector_machine as SVC\n",
    "import model.naive_bayesian_classifier as NB\n",
    "import model.convolutional_neural_network as CNN\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "torch.manual_seed(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Processing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 1e+03 ns, total: 3 µs\n",
      "Wall time: 5.25 µs\n",
      "\n",
      "Preprocessing of data...\n",
      "\n",
      "Parsing news dataset from file: kaggle_raw/Fake.csv\n",
      "Setting label for news dataset: FAKE\n",
      "\n",
      "Preview of Fake news Dataset\n",
      "                                                   title  \\\n",
      "0      FLASHBACK: KING OBAMA COMMUTES SENTENCES OF 22...   \n",
      "1      APPLE‚ÄôS CEO SAYS RELIGIOUS FREEDOM LAWS ARE ...   \n",
      "2      WATCH DIRTY HARRY REID ON HIS LIE ABOUT ROMNEY...   \n",
      "3      OH NO! GUESS WHO FUNDED THE SHRINE TO TED KENNEDY   \n",
      "4      BENGHAZI PANEL CALLS HILLARY TO TESTIFY UNDER ...   \n",
      "...                                                  ...   \n",
      "23445  IT BEGINS‚Ä¶RINO MEGA-DONOR Threatens Jeb Bush...   \n",
      "23446  BUSTED! Maxine Waters‚Äô Ties to Black Nationa...   \n",
      "23447  Democrat Senator Warns Mueller Not To Release ...   \n",
      "23448  MSNBC ANCHOR Flabbergasted at What Texas Teach...   \n",
      "23449  WATCH: SNOWFLAKES ASKED Communist Party Platfo...   \n",
      "\n",
      "                                                    text   subject       date  \\\n",
      "0      Just making room for Hillary President Obama t...  politics 2015-03-31   \n",
      "1      The gay mafia has a new corporate  Don. This i...  politics 2015-03-31   \n",
      "2      In case you missed it Sen. Harry Reid (R-NV), ...  politics 2015-03-31   \n",
      "3      Nothing like political cronyism to make your s...  politics 2015-03-31   \n",
      "4      Does anyone really think Hillary Clinton will ...  politics 2015-03-31   \n",
      "...                                                  ...       ...        ...   \n",
      "23445  A longtime Republican Party donor based in Flo...  politics 2018-02-18   \n",
      "23446  We reported that Maxine Waters and members of ...  politics 2018-02-18   \n",
      "23447  According to The Hill, Democrat Senator Bob Ca...  politics 2018-02-19   \n",
      "23448  If we protect every other government building ...  politics 2018-02-19   \n",
      "23449  Ami Horowitz is fantastic! Check out this man ...  politics 2018-02-19   \n",
      "\n",
      "      label  \n",
      "0      FAKE  \n",
      "1      FAKE  \n",
      "2      FAKE  \n",
      "3      FAKE  \n",
      "4      FAKE  \n",
      "...     ...  \n",
      "23445  FAKE  \n",
      "23446  FAKE  \n",
      "23447  FAKE  \n",
      "23448  FAKE  \n",
      "23449  FAKE  \n",
      "\n",
      "[23450 rows x 5 columns]\n",
      "\n",
      "Parsing news dataset from file: kaggle_raw/True.csv\n",
      "Setting label for news dataset: REAL\n",
      "\n",
      "Preview of Real news Dataset\n",
      "                                                   title  \\\n",
      "0      As U.S. budget fight looms, Republicans flip t...   \n",
      "1      U.S. military to accept transgender recruits o...   \n",
      "2      Senior U.S. Republican senator: 'Let Mr. Muell...   \n",
      "3      FBI Russia probe helped by Australian diplomat...   \n",
      "4      Trump wants Postal Service to charge 'much mor...   \n",
      "...                                                  ...   \n",
      "21412  'Fully committed' NATO backs new U.S. approach...   \n",
      "21413  LexisNexis withdrew two products from Chinese ...   \n",
      "21414  Minsk cultural hub becomes haven from authorities   \n",
      "21415  Vatican upbeat on possibility of Pope Francis ...   \n",
      "21416  Indonesia to buy $1.14 billion worth of Russia...   \n",
      "\n",
      "                                                    text       subject  \\\n",
      "0      WASHINGTON (Reuters) - The head of a conservat...  politicsNews   \n",
      "1      WASHINGTON (Reuters) - Transgender people will...  politicsNews   \n",
      "2      WASHINGTON (Reuters) - The special counsel inv...  politicsNews   \n",
      "3      WASHINGTON (Reuters) - Trump campaign adviser ...  politicsNews   \n",
      "4      SEATTLE/WASHINGTON (Reuters) - President Donal...  politicsNews   \n",
      "...                                                  ...           ...   \n",
      "21412  BRUSSELS (Reuters) - NATO allies on Tuesday we...     worldnews   \n",
      "21413  LONDON (Reuters) - LexisNexis, a provider of l...     worldnews   \n",
      "21414  MINSK (Reuters) - In the shadow of disused Sov...     worldnews   \n",
      "21415  MOSCOW (Reuters) - Vatican Secretary of State ...     worldnews   \n",
      "21416  JAKARTA (Reuters) - Indonesia will buy 11 Sukh...     worldnews   \n",
      "\n",
      "            date label  \n",
      "0     2017-12-31  REAL  \n",
      "1     2017-12-29  REAL  \n",
      "2     2017-12-31  REAL  \n",
      "3     2017-12-30  REAL  \n",
      "4     2017-12-29  REAL  \n",
      "...          ...   ...  \n",
      "21412 2017-08-22  REAL  \n",
      "21413 2017-08-22  REAL  \n",
      "21414 2017-08-22  REAL  \n",
      "21415 2017-08-22  REAL  \n",
      "21416 2017-08-22  REAL  \n",
      "\n",
      "[21417 rows x 5 columns]\n",
      "\n",
      "Parsing scraped news from file: scraped_raw/scraped_articles.json\n",
      "\n",
      "Preview of Scraped news Dataset\n",
      "1653\n",
      "                                                  title  \\\n",
      "0     Bangladesh moves hundreds of Rohingya refugees...   \n",
      "1     Hundreds of Rohingya refugees being relocated ...   \n",
      "2     'I'm the guy who's stealing Christmas': Canadi...   \n",
      "3     Before this teacher, school attendance was as ...   \n",
      "4     Amid China-US tensions, Australia finds itself...   \n",
      "...                                                 ...   \n",
      "1648  Where Dogs Roam Free Forever, Saved from Eutha...   \n",
      "1649        Video Catches Mouse’s Soul Leaving His Body   \n",
      "1650  Colorado Fast-Food Chain Sonic Now Selling Wee...   \n",
      "1651  This 93 Year Old Woman Shares The Recipes She ...   \n",
      "1652  [VIDEO] Teen Blogger Tells Girls To Stay With ...   \n",
      "\n",
      "                                                   text       date label  \n",
      "0     (CNN) Hundreds of Rohingya refugees in Banglad... 2020-12-03  REAL  \n",
      "1     Hundreds of Rohingya refugees in Bangladesh ar... 2020-12-05  REAL  \n",
      "2     As coronavirus cases rise, Manitoba Premier Br... 2020-12-04  REAL  \n",
      "3     Ranjitsinh Disale, a teacher in India, was hon... 2020-12-04  REAL  \n",
      "4     The relationship between China and Australia h... 2020-12-04  REAL  \n",
      "...                                                 ...        ...   ...  \n",
      "1648  Over 2,500 dogs are already enjoying a better ... 2020-11-20  FAKE  \n",
      "1649  Video Catches Mouse’s Soul Leaving His Body.\\n... 2020-10-31  FAKE  \n",
      "1650  Colorado Fast-Food Chain Sonic Now Selling Wee... 2014-01-03  FAKE  \n",
      "1651  The Great Depression was a time of struggle an... 2015-11-25  FAKE  \n",
      "1652  [VIDEO] Teen Blogger Tells Girls To Stay With ... 2014-12-02  FAKE  \n",
      "\n",
      "[1653 rows x 4 columns]\n",
      "\n",
      "Tokenizing fake_news dataset, this may take a few minutes...\n",
      "Tokenizing real_news dataset, this may take a few minutes...\n",
      "\n",
      "\n",
      "Splitting data: 70% training, 30% testing\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "# change param of use_full_dataset to True to use full data set\n",
    "# Warning: may take an hour or longer to train all models using full dataset!)\n",
    "use_full_dataset = True\n",
    "\n",
    "if(not use_full_dataset) : tools.set_results_dir(\"./results/mock_results/\")\n",
    "    \n",
    "X_train, X_test, y_train, y_test = preprocess.preprocess(use_full_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Classifier \n",
    "## Hyperparameter search + training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "# Logisitic Regression Classifier\n",
    "print(\"Testing Logistic Regression Classifier ...\\n\")\n",
    "\n",
    "# set the hyperparams\n",
    "C = np.logspace(-4,4,9)\n",
    "param_grid = {\"C\":C}\n",
    "\n",
    "# fetch all the estimators given the chosen hyperparameters\n",
    "estimators = LR.train_all_estimators(X_train, y_train, C)\n",
    "\n",
    "# perform hyperparam search\n",
    "grid_search = LR.perform_hyperparam_grid_search(X_train,y_train, param_grid)\n",
    "\n",
    "best_estimator = grid_search.best_estimator_\n",
    "hyperparams = grid_search.best_params_\n",
    "score = grid_search.best_score_*100\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate estimator scores and overall overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the training and testing scores and plot the result\n",
    "trn_scores, test_scores = tools.calculate_estimator_scores([X_train, X_test, y_train, y_test], estimators)\n",
    "\n",
    "# calculate model overfitting\n",
    "overfitting = tools.determine_overfitting(trn_scores,test_scores)\n",
    "print(\"\\nLogistic Regression overfitting: {:.3f}\\n\".format(overfitting))\n",
    "\n",
    "# display details of best estimator\n",
    "tools.display_best_estimator(score, \"LogisticRegression\", hyperparams)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the scores of each estimator (see test_results or results folder for png files of graphs)\n",
    "tools.plot_estimator_scores(\"LogisticRegressbion\",trn_scores,test_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use best estimator to make predictions\n",
    "y_pred = LR.logistic_regression_predict(best_estimator, X_test)\n",
    "tools.display_prediction_scores(y_test,y_pred)\n",
    "\n",
    "tools.plot_predicted_labels(y_test, y_pred, \"LogisticRegression\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tools.plot_confusion_matrix(y_test,y_pred,\"LogisticRegression\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Decision Tree Classifier\n",
    "## Hyperparameter search + training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "print(\"Testing Decision Tree Classifier ...\\n\")\n",
    "\n",
    "# set the hyperparams\n",
    "D = np.linspace(2,30,15)\n",
    "param_grid = {\"max_depth\":D}\n",
    "\n",
    "# fetch all the estimators given the chosen hyperparameters\n",
    "estimators = DT.train_all_estimators(X_train, y_train, D)\n",
    "\n",
    "# perform hyperparam search\n",
    "grid_search = DT.perform_hyperparam_grid_search(X_train,y_train, param_grid)\n",
    "\n",
    "best_estimator = grid_search.best_estimator_\n",
    "hyperparams = grid_search.best_params_\n",
    "score = grid_search.best_score_ * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Features Importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools.plot_feature_importances(X_train, best_estimator, \"DecisionTree\", savefig=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate estimator scores and overall overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# calculate the training and testing scores and plot the result\n",
    "trn_scores, test_scores = tools.calculate_estimator_scores([X_train, X_test, y_train, y_test], estimators)\n",
    "\n",
    "# calculate model overfitting\n",
    "overfitting = tools.determine_overfitting(trn_scores,test_scores)\n",
    "print(\"\\nDecision Tree overfitting: {:.3f}\\n\".format(overfitting))\n",
    "\n",
    "# plot the scores of each estimator\n",
    "tools.plot_estimator_scores(\"DecisionTree\",trn_scores,test_scores)\n",
    "\n",
    "# display details of best estimator\n",
    "tools.display_best_estimator(score, \"DecisionTree\", hyperparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use best estimator to make predictions\n",
    "y_pred = DT.decision_tree_predict(best_estimator, X_test)\n",
    "tools.display_prediction_scores(y_test,y_pred)\n",
    "\n",
    "tools.plot_predicted_labels(y_test, y_pred, \"DecisionTree\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools.plot_confusion_matrix(y_test,y_pred,\"DecisionTree\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier\n",
    "## Hyperparameter search + training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "\n",
    "print(\"Testing Random Forest Classifier ...\\n\")\n",
    "\n",
    "# set the hyperparams\n",
    "D = np.linspace(2,14,7)\n",
    "N = np.linspace(2,20,10, dtype=\"int32\")\n",
    "\n",
    "param_grid = {\"max_depth\":D, \"n_estimators\": N}\n",
    "\n",
    "# fetch all the estimators given the chosen hyperparameters\n",
    "estimators = RF.train_all_estimators(X_train,y_train,D,N)\n",
    "\n",
    "# perform hyperparam search\n",
    "grid_search = RF.perform_hyperparam_grid_search(X_train,y_train, param_grid)\n",
    "\n",
    "best_estimator = grid_search.best_estimator_\n",
    "hyperparams = grid_search.best_params_\n",
    "score = grid_search.best_score_*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Feature Importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools.plot_feature_importances(X_train, best_estimator, \"RandomForest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Estimator scores and Overall Overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the training and testing scores and plot the result\n",
    "trn_scores, test_scores = tools.calculate_estimator_scores([X_train, X_test, y_train, y_test], estimators)\n",
    "\n",
    "# calculate model overfitting\n",
    "overfitting = tools.determine_overfitting(trn_scores,test_scores)\n",
    "print(\"\\nRandom Forest overfitting: {:.3f}\\n\".format(overfitting))\n",
    "\n",
    "# plot the scores of each estimator\n",
    "tools.plot_estimator_scores(\"RandomForest\",trn_scores,test_scores)\n",
    "\n",
    "# display details of best estimator\n",
    "tools.display_best_estimator(score, \"RandomForest\", hyperparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use best estimator to make predictions\n",
    "y_pred = RF.random_forest_predict(best_estimator, X_test)\n",
    "\n",
    "tools.plot_predicted_labels(y_test, y_pred, \"RandomForest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools.plot_confusion_matrix(y_test,y_pred,\"RandomForest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine Classifier\n",
    "## Hyperparameter search + training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "print(\"Testing SVM Classifier ...\\n\")\n",
    "\n",
    "# set the hyperparams\n",
    "C = np.logspace(-2,3,6)\n",
    "G = np.logspace(-2,3,6)\n",
    "K = [\"rbf\", \"linear\"]\n",
    "\n",
    "param_grid = {\"C\":C, \"gamma\": G, \"kernel\": K}\n",
    "\n",
    "# fetch all the estimators given the chosen hyperparameters\n",
    "estimators = SVC.train_all_estimators(X_train, y_train, C, G, K)\n",
    "\n",
    "# perform hyperparam search\n",
    "grid_search = SVC.perform_hyperparam_grid_search(X_train,y_train, param_grid)\n",
    "\n",
    "best_estimator = grid_search.best_estimator_\n",
    "hyperparams = grid_search.best_params_\n",
    "score = grid_search.best_score_*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Estimator scores and Overall Overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the training and testing scores and plot the result\n",
    "trn_scores, test_scores = tools.calculate_estimator_scores([X_train, X_test, y_train, y_test], estimators)\n",
    "\n",
    "# calculate model overfitting\n",
    "overfitting = tools.determine_overfitting(trn_scores,test_scores)\n",
    "print(\"\\nSVC overfitting: {:.3f}\\n\".format(overfitting))\n",
    "\n",
    "# plot the scores of each estimator\n",
    "tools.plot_estimator_scores(\"SVC\",trn_scores,test_scores)\n",
    "\n",
    "# display details of best estimator\n",
    "tools.display_best_estimator(score, \"SVC\", hyperparams)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use best estimator to make predictions\n",
    "y_pred = SVC.support_vector_machine_predict(best_estimator, X_test)\n",
    "\n",
    "tools.plot_predicted_labels(y_test, y_pred, \"SVC\")\n",
    "tools.display_prediction_scores(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools.plot_confusion_matrix(y_test,y_pred,\"SVC\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Classifier\n",
    "## Hyperparameter search + training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Testing Naive Bayesian Classifier ...\\n\")\n",
    "\n",
    "# set the hyperparams\n",
    "A = np.logspace(-4,4,9)\n",
    "F = [True, False]\n",
    "param_grid = {\"alpha\":A, \"fit_prior\":F}\n",
    "\n",
    "# fetch all the estimators given the chosen hyperparameters\n",
    "estimators = NB.train_all_estimators(X_train, y_train, A , F)\n",
    "\n",
    "# perform hyperparam search\n",
    "grid_search = NB.perform_hyperparam_grid_search(X_train,y_train, param_grid)\n",
    "\n",
    "best_estimator = grid_search.best_estimator_\n",
    "hyperparams = grid_search.best_params_\n",
    "score = grid_search.best_score_*100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Estimator scores and Overall Overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the training and testing scores and plot the result\n",
    "trn_scores, test_scores = tools.calculate_estimator_scores([X_train, X_test, y_train, y_test], estimators)\n",
    "\n",
    "# calculate model overfitting\n",
    "overfitting = tools.determine_overfitting(trn_scores,test_scores)\n",
    "print(\"\\nNaive Bayes overfitting: {:.3f}\\n\".format(overfitting))\n",
    "\n",
    "# plot the scores of each estimator\n",
    "tools.plot_estimator_scores(\"NaiveBayes\",trn_scores,test_scores)\n",
    "\n",
    "# display details of best estimator\n",
    "tools.display_best_estimator(score, \"NaiveBayes\", hyperparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use best estimator to make predictions\n",
    "y_pred = NB.naive_bayesian_predict(best_estimator, X_test)\n",
    "\n",
    "tools.plot_predicted_labels(y_test, y_pred, \"NaiveBayes\", True)\n",
    "tools.display_prediction_scores(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools.plot_confusion_matrix(y_test,y_pred,\"NaiveBayes\", True)\n",
    "\n",
    "tools.display_result(best_estimator, X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning - Convolutional Neural Network Classifier\n",
    "\n",
    "### Now we compare deep learning classification to our traditional Machine Learning models...\n",
    "\n",
    "## Set model and training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params for CNN model\n",
    "seq_len = 224\n",
    "if use_full_dataset: \n",
    "    seq_len = 216\n",
    "    \n",
    "model_params = {\n",
    "    # text preprocessing\n",
    "    \"seq_len\": seq_len,\n",
    "    \"num_words\": 10000,\n",
    "    \"embedding_size\": 64,\n",
    "\n",
    "    # size of convolution outputs\n",
    "    \"conv_out_size\": 32,\n",
    "\n",
    "    # Number of strides for each convolution\n",
    "    \"stride\": 2,\n",
    "\n",
    "    # kernel sizes\n",
    "    \"kernel_sizes\": [2,3,4,5]\n",
    "}\n",
    "\n",
    "# training parameters\n",
    "epochs = 24\n",
    "batch_size = 108\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct the CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN.CnnModel(model_params)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred, train_accuracies, test_accuracies, train_losses, test_losses \\\n",
    "    = CNN.train_cnn(\n",
    "        model, \n",
    "        X_train, \n",
    "        X_test, \n",
    "        y_train, \n",
    "        y_test, \n",
    "        epochs, \n",
    "        batch_size, \n",
    "        learning_rate\n",
    "    )\n",
    "print(train_accuracies[0], test_accuracies[0], train_losses[0], test_losses[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Training + Test Prediction Accuracies for each Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools.plot_cnn_accuracies(train_accuracies,test_accuracies, \"CNN\", epochs, batch_size, learning_rate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Training + Test Prediction Losses for each Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools.plot_cnn_losses(train_losses, test_losses, \"CNN\", epochs, batch_size, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
